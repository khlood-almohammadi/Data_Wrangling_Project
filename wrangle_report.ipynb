{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                  .-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                                    \n",
    "                                    \n",
    "                                    \n",
    "                                        Wrangel Report\n",
    "                                    By Khlood al mohammadi\n",
    "                                      Date: 5 /11 / 2020     \n",
    "                \n",
    "           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                               \n",
    "                 .-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](p2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### in this project,\n",
    "\n",
    "The biggest challenge occurred in data science and analysis from my point of view, as the whole project started from the beginning, which is to collect data from different sources and in multiple formats, then move to reading it, then work to understand this data and what is intended and try to link it to the project objectives and then move to the stage that It took about 80% of the project preparation time, which is the stage of cleaning and organizing the data and disposing of the columns that are not related to the goals or are useless.\n",
    "\n",
    "The project went through the following stages:\n",
    "\n",
    "\n",
    "### The first stage :\n",
    "Collecting and reading data. It is good that Udacity provided us with files in private lectures. The ability to search for and chase them within the sites was very difficult. There was a slight problem with the file: \n",
    "                                      \n",
    "                                  (image-Forecastions (1) .tsv)\n",
    "\n",
    "        because in a different format we needed to activate the `code` to make it readable:\n",
    "    \n",
    "                            ('image-Forecastions (1) .tsv', sep = '\\ t')\n",
    "\n",
    "\n",
    "### The second phase : \n",
    "\n",
    "Cleaning and processing data, searching for missing data, `adding` the required, and getting rid of columns that do not serve the analysis, also merging similar columns and have the same classification, as each of the columns was merged: (doggo,\tfloofer, pupper, puppo) under the name (breeds), and I also followed a step that helped me a lot, which is the subtraction A set of questions at the beginning, then testing these questions at the end of the data processing process to make sure that the goals were achieved first, and that in my opinion, all the problems were solved correctly, and one of the good things that happened here is to add a column for (years), (month / Year) in each of the data_json saved in the Twitter archive after this stage, the files were saved, processed and cleaned under each group\n",
    "\n",
    "\n",
    "\n",
    "### Finally :\n",
    "\n",
    "Analyzing data, showing results, presenting graphic visualizations, narrating stories, results, conclusions and perceptions. The three files were combined into one table for later use.\n",
    "\n",
    "\n",
    "\n",
    ".\n",
    ".\n",
    ".\n",
    ".\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](p8.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
